# Azure Databricks Build Pipeline
# azure-pipelines.yml

trigger:
  branches:
    include:
    - '*'
  tags:
    include:
    - '*'

pool:
  vmImage: 'ubuntu-latest'

jobs:
- job: Tests
  condition: eq(variables['Build.Reason'], 'PullRequest')
  steps:
  - task: UsePythonVersion@0
    displayName: 'Use Python 3.7'
    inputs:
      versionSpec: 3.7

  - checkout: self
    persistCredentials: true
    clean: true

  - script: pip install databricks-cli requests
    displayName: 'Install python dependencies'

  - script: |
      echo "[DEFAULT]" >> ~/.databrickscfg
      echo "host = $(WORKSPACE_URL)" >> ~/.databrickscfg
      echo "token = $(PAT)" >> ~/.databrickscfg
    displayName: 'Set up databricks cli'

  - script: |
      databricks workspace import_dir -o $(Build.Repository.LocalPath)/notebooks /Users/florent.moiny@databricks.com/demo/structure-evolution/ci-cd-staging/
    displayName: 'Copy notebooks to staging directory'

  - script: python $(Build.Repository.LocalPath)/ci-cd-scripts/test-staging-model.py --url $(WORKSPACE_URL) --pat $(PAT)
    displayName: 'Test staging model'


# run build phase only on tags
- job: Build
  condition: startsWith(variables['Build.SourceBranch'], 'refs/tags/')
  steps:
  - checkout: self
    persistCredentials: true
    clean: true

  - script: |
      cp $(Build.Repository.LocalPath)/model.json $(Build.ArtifactStagingDirectory)/
      cp $(Build.Repository.LocalPath)/ci-cd-scripts/transition-staging-model-to-prod.py $(Build.ArtifactStagingDirectory)/
      mkdir -p $(Build.ArtifactStagingDirectory)/notebooks
      cp $(Build.Repository.LocalPath)/notebooks/* $(Build.ArtifactStagingDirectory)/notebooks/
    displayName: 'Copy notebooks, model.json, and transition script to common directory'

  - task: PublishBuildArtifacts@1
    inputs:
      pathToPublish: '$(Build.ArtifactStagingDirectory)'
      ArtifactName: '$(Build.Repository.Name)-bundle'
